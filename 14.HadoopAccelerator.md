标签：Apache-Ignite-1.4.0-中文开发手册

[TOC]
#14.Hadoop加速器
## 14.1.Hadoop加速器
Ignite Hadoop加速器提供了一个组件集来进行内存Hadoop作业执行以及文件系统操作。
### 14.1.1.MapReduce
Hadoop加速器提供了一个高性能的作业跟踪器实现，替代了标准的Hadoop MapReduce，使用它可以提高Hadoop MapReduce作业执行的性能。
### 14.1.2.IGFS-内存文件系统
Hadoop加速器提供了一个Hadoop`FileSystem`实现，它通过分布式Ignite文件系统(`IGFS`)在内存内存储文件系统数据，使用它可以最小化磁盘IO以及改进任何文件系统操作的性能。
### 14.1.3.第二文件系统
Hadoop加速器提供了一个`SecondaryFileSystem`的实现，这个实现可以注入已有的IGFS以在任何其他的Hadoop`FileSystem`实现上进行通读和通写操作（比如HDFS）。如果希望在基于磁盘的`HDFS`或者任何其他的Hadoop兼容文件系统上建立一个内存缓存层，那么可以使用它。
### 14.1.4.支持的Hadoop发行版
Ignite Hadoop加速器可以用于一系列的Hadoop发行版，每个发行版都需要一个特定的安装步骤。
## 14.2.MapReduce
Ignite内存MapReduce可以有效地对处理存储在任何Hadoop文件系统上的数据并行化，他在提供了低延迟，HPC样式的分布式处理的同时还消除了与标准Hadoop架构中的作业跟踪器和任务跟踪器有关的开销。
![](https://www.filepicker.io/api/file/aPKj2pqhRJuciy6AqFme)
### 14.2.1.配置Ignite
Ignite Hadoop加速器MapReduce引擎在Ignite集群中处理Hadoop作业，必须满足若干前提条件：

 - 必须设置`IGNITE_HOME`环境变量并且指向Ignite的安装根目录；
 - 每个集群节点在类路径中必须包含Hadoop的jar文件，可以参照Ignite针对各个Hadoop发行版的安装向导来了解详细信息；
 - 集群节点通过监听特定的Socket来接收作业执行的请求。默认的话每个Ignite节点都会监听来自`127.0.0.1:11211`的请求，可以通过`ConnectorConfiguration`类来改写默认的主机和端口。

XML：
```xml
<bean class="org.apache.ignite.configuration.IgniteConfiguration">
  ...
  <property name="connectorConfiguration">
    <list>
      <bean class="org.apache.ignite.configuration.ConnectorConfiguration">
        <property name="host" value="myHost" />
        <property name="port" value="12345" />        
      </bean>
    </list>    
  </property>
</bean>
```
### 14.2.2.运行Ignite
配置Ignite节点后用如下方法启动：
```shell
$ bin/ignite.sh
```
### 14.2.3.配置Hadoop
要通过Ignite作业跟踪器运行Hadoop作业需要满足一些必要条件：

 - 必须设置`IGNITE_HOME`环境变量并且指向Ignite的安装根目录；
 - Hadoop在类路径中必须包含Ignite Jars:`${IGNITE_HOME}\libs\ignite-core-[version].jar`以及`${IGNITE_HOME}\libs\hadoop\ignite-hadoop-[version].jar`，这可以通过几种方式实现：
    - 将这几个jar文件加入`HADOOP_CLASSPATH`环境变量中；
    - 将这些jar文件拷贝或者建立符号链接到Hadoop存放共享库的文件夹中，可以参照Ignite针对各个Hadoop发行版的安装向导来了解详细信息；
 - Hadoop作业必须配置使用Ignite作业跟踪器，有两个配置属性负责这个：
     - `mapreduce.framework.name`：必须设置为`ignite`；
     - `mapreduce.jobtracker.address`：必须设置为Ignite节点监听的主机/端口；

这仍然可以通过几种方式实现，**首先**，可以创建独立的带有这些配置属性的`mapred-site.xml`文件然后将其用于作业执行：
XML：
```xml
<configuration>
  ...
  <property>
    <name>mapreduce.framework.name</name>
    <value>ignite</value>
  </property>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>127.0.0.1:11211</value>
  </property>
  ...
</configuration>
```
**第二**，可以覆写Hadoop安装的`mapred-site.xml`，这会强制所有Hadoop作业默认选择Ignite作业跟踪器，除非通过某种方式在作业级覆写。
**第三**，可以为特定的作业通过编程方式设置这些属性：
```java
Configuration conf = new Configuration();
...
conf.set(MRConfig.FRAMEWORK_NAME,  IgniteHadoopClientProtocolProvider.FRAMEWORK_NAME);
conf.set(MRConfig.MASTER_ADDRESS, "127.0.0.1:11211);
...
Job job = new Job(conf, "word count");
...
```
### 14.2.4.运行Hadoop
如何运行一个作业取决于如何配置Hadoop：
如果配置了独立的`mapred-site.xml`：
```shell
hadoop --config [path_to_config] [arguments]
```
如果修改了默认的`mapred-site.xml`，那么`--config`选项就不是必要的了：
```shell
hadoop [arguments]
```
如果通过编程方式启动作业，那么像下面这样提交他：
```java
...
Job job = new Job(conf, "word count");
...
job.submit();
```
## 14.3.在Apache Hadoop上安装
本章节描述了如何在Apache Hadoop发行版上安装Ignite Hadoop加速器。
### 14.3.1.Ignite

 - 下载最新版本的Ignite Hadoop加速器然后解压到某处；
 - 设置`IGNITE_HOME`环境变量，指向上一步Ignite Hadoop加速器的解压目录；
 - 确保`HADOOP_HOME`环境变量设置正确，这对于Ignite查找必须的Hadoop的类是必要的；
 - 如果打算使用Ignite`FileSystem`实现，需要在配置文件中配置`IGFS`（默认配置文件是`${IGNITE_HOME}/config/default-config.xml`）；
XML：
```xml
<bean class="org.apache.ignite.configuration.IgniteConfiguration">
  ...
  <property name="fileSystemConfiguration">
    <list>
      <bean class="org.apache.ignite.configuration.FileSystemConfiguration">
        <property name="metaCacheName" value="myMetaCache" />
        <property name="dataCacheName" value="myDataCache" />       
      </bean>
    </list>    
  </property>
  ...
</bean>
```
使用这个配置的IGFS会监听来自绑定到`127.0.0.1:10500`的默认端点的文件系统请求。
如果希望覆写它，需要提供替代的`ipcEndpointConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。

 - 如果希望对作业使用IgniteMapReduce引擎，不需要进行额外的配置，因为节点会监听来自绑定到`127.0.0.1:11211`的默认端点的作业执行请求。
如果希望覆写它，需要提供替代的`connectorConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。
到这一步Ignite节点已经准备好启动了：
```shell
$ bin/ignite.sh
```
### 14.3.2.Hadoop

 - 确保设置IGNITE_HOME环境变量，指向Ignite Hadoop加速器的解压目录；
 - 停止所有的Hadoop服务；
 - 将Ignite的jars`${IGNITE_HOME}\libs\ignite-core-[version].jar`和`${GNITE_HOME}\libs\hadoop\ignite-hadoop-[version].jar`加入Hadoop的类路径，也可以拷贝（或符号链接）这些jar文件到Hadoop环境（比如`${HADOOP_HOME}/share/hadoop/common/lib`）
```shell
ln -s ${IGNITE_HOME}/libs/ignite-core-1.0.0.jar ${HADOOP_HOME}/share/hadoop/common/lib/ignite-core-1.0.0.jar
ln -s ${IGNITE_HOME}/libs/hadoop/ignite-hadoop-1.0.0.jar ${HADOOP_HOME}/share/hadoop/common/lib/ignite-hadoop-1.0.0.jar
```
或者将他们加入`HADOOP_CLASSPATH`环境变量：
```shell
export HADOOP_CLASSPATH=${IGNITE_HOME}/libs/ignite-core-1.0.0.jar:${IGNITE_HOME}/libs/ignite-hadoop/ignite-hadoop-1.0.0.jar
```
 - 如果希望使用Ignite`文件系统`，可以在独立的`core-site.xml`文件中或者在默认的位于`${HADOOP_HOME}/etc/hadoop`的`core-site.xml`中进行配置。
```xml
<configuration>
  ...
  <property>
    <name>fs.default.name</name>
    <value>igfs:///</value>
  </property>
  ...
  <property>
    <name>fs.igfs.impl</name>
    <value>org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem</value>
  </property>  
  ...
</configuration>
```
注意如果改变了位于默认的`core-site.xml`中的`fs.default.name`来使用Ignite文件系统，Hadoop就不会再使用`HDFS`,如果希望同时使用Ignite`文件系统`和`HDFS`,可以考虑创建单独的配置文件。

 - 如果希望使用Ignite`MapReduce`作业跟踪器，可以在独立的`mapred-site.xml`文件中或者在默认的位于`${HADOOP_HOME}/etc/hadoop`的`mapred-site.xml`中进行配置：
XML：
```xml
<configuration>
  ...
  <property>
    <name>mapreduce.framework.name</name>
    <value>ignite</value>
  </property>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>127.0.0.1:11211</value>
  </property>
  ...
</configuration>
```
 - 启动Hadoop；
 - 到这一步安装已经完成然后就可以启动运行作业了。
可以通过单独的`core-site.xml`以及/或者`mapred-site.xml`配置文件来运行作业：
```shell
hadoop --config [path_to_config] [arguments]
```
通过默认的配置运行作业:
```shell
hadoop [arguments]
```
## 14.4.在Cloudera CDH上安装
本章节描述了如何在Cloudera CDH发行版上安装Ignite Hadoop加速器。
### 14.4.1.Ignite

 - 下载最新版本的Ignite Hadoop加速器然后解压到某处；
 - 设置`IGNITE_HOME`环境变量，指向上一步Ignite Hadoop加速器的解压目录；
 - 如果打算使用Ignite`FileSystem`实现，需要在配置文件中配置`IGFS`（默认配置文件是`${IGNITE_HOME}/config/default-config.xml`）；
XML：
```xml
<bean class="org.apache.ignite.configuration.IgniteConfiguration">
  ...
  <property name="fileSystemConfiguration">
    <list>
      <bean class="org.apache.ignite.configuration.FileSystemConfiguration">
        <property name="metaCacheName" value="myMetaCache" />
        <property name="dataCacheName" value="myDataCache" />       
      </bean>
    </list>    
  </property>
  ...
</bean>
```
使用这个配置的IGFS会监听来自绑定到`127.0.0.1:10500`的默认端点的文件系统请求。
如果希望覆写它，需要提供替代的`ipcEndpointConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。

 - 如果希望对作业使用IgniteMapReduce引擎，不需要进行额外的配置，因为节点会监听来自绑定到`127.0.0.1:11211`的默认端点的作业执行请求。
如果希望覆写它，需要提供替代的`connectorConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。
到这一步Ignite节点已经准备好启动了：
```shell
$ bin/ignite.sh
```
### 14.4.2.CDH

 - 确保设置IGNITE_HOME环境变量，指向Ignite Hadoop加速器的解压目录；
 - 打开**Cloudera Manager**然后关闭除了**Cloudera Management Services**之外的所有CDH服务；
 - 将Ignite的jars`${IGNITE_HOME}\libs\ignite-core-[version].jar`和`${GNITE_HOME}\libs\hadoop\ignite-hadoop-[version].jar`加入CDH的类路径，也可以拷贝（或符号链接）这些jar文件：
```shell
ln -s ${IGNITE_HOME}/libs/ignite-core-1.0.0.jar [path_to_CDH]/lib/hadoop/lib /ignite-core-1.0.0.jar
ln -s ${IGNITE_HOME}/libs/hadoop/ignite-hadoop-1.0.0.jar [path_to_CDH]/lib/hadoop/lib/ignite-hadoop-1.0.0.jar
```
 - 如果希望使用Ignite`文件系统`，可以在独立的`core-site.xml`文件中进行配置。
```xml
<configuration>
  ...
  <property>
    <name>fs.default.name</name>
    <value>igfs:///</value>
  </property>
  ...
  <property>
    <name>fs.igfs.impl</name>
    <value>org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem</value>
  </property>  
  ...
</configuration>
```
作为替代也可以在默认的CDH`core-site.xml`中配置这些属性：**Cloudera Manager**->**YARN (MR2 Included)**->**Configuration**->**Service Wide**->**Advanced**->**YARN Service Advanced Configuration Snippet (Safety Valve) for core-site.xml**。
注意如果改变了位于默认的`core-site.xml`中的`fs.default.name`来使用Ignite文件系统，CDH就不会再使用`HDFS`,如果希望同时使用Ignite`文件系统`和`HDFS`,可以考虑创建单独的配置文件。

 - 如果希望使用Ignite`MapReduce`作业跟踪器，可以在独立的`mapred-site.xml`文件中进行配置：
XML：
```xml
<configuration>
  ...
  <property>
    <name>mapreduce.framework.name</name>
    <value>ignite</value>
  </property>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>127.0.0.1:11211</value>
  </property>
  ...
</configuration>
```
作为替代也可以在默认的CDH`mapred-site.xml`中配置这些属性：**Cloudera Manager**->**YARN (MR2 Included)**->**Configuration**->**Service Wide**->**Advanced**->**YARN Service MapReduce Advanced Configuration Snippet (Safety Valve)**。

 - 如果对默认的配置做了任何改变，需要保存然后重新部署。
 - 启动CDH服务；
 - 到这一步安装已经完成然后就可以启动运行作业了。
可以通过单独的`core-site.xml`以及/或者`mapred-site.xml`配置文件来运行作业：
```shell
hadoop --config [path_to_config] [arguments]
```
通过默认的配置运行作业:
```shell
hadoop [arguments]
```
## 14.5.在Hortonworks HDP上安装
本章节描述了如何在Hortonworks HDP发行版上安装Ignite Hadoop加速器。
### 14.5.1.Ignite

 - 下载最新版本的Ignite Hadoop加速器然后解压到某处；
 - 设置`IGNITE_HOME`环境变量，指向上一步Ignite Hadoop加速器的解压目录；
 - 要让Ignite查找必要的HDP jar文件，用下面的内容创建一个`/etc/default/hadoop`文件：
```shell
HDP=/usr/hdp/current
export HADOOP_HOME=$HDP/hadoop-client/
export HADOOP_COMMON_HOME=$HDP/hadoop-client/
export HADOOP_HDFS_HOME=$HDP/hadoop-hdfs-client/ 
export HADOOP_MAPRED_HOME=$HDP/hadoop-mapreduce-client/
```
 - 如果打算使用Ignite`文件系统`实现，需要在配置文件中配置`IGFS`（默认配置文件是`${IGNITE_HOME}/config/default-config.xml`）；
XML：
```xml
<bean class="org.apache.ignite.configuration.IgniteConfiguration">
  ...
  <property name="fileSystemConfiguration">
    <list>
      <bean class="org.apache.ignite.configuration.FileSystemConfiguration">
        <property name="metaCacheName" value="myMetaCache" />
        <property name="dataCacheName" value="myDataCache" />       
      </bean>
    </list>    
  </property>
  ...
</bean>
```
使用这个配置的IGFS会监听来自绑定到`127.0.0.1:10500`的默认端点的文件系统请求。
如果希望覆写它，需要提供替代的`ipcEndpointConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。

 - 如果希望对作业使用IgniteMapReduce引擎，不需要进行额外的配置，因为节点会监听来自绑定到`127.0.0.1:11211`的默认端点的作业执行请求。
如果希望覆写它，需要提供替代的`connectorConfiguration`（可以参照`13.2.IGFS作为Hadoop文件系统`章节）。
到这一步Ignite节点已经准备好启动了：
```shell
$ bin/ignite.sh
```
### 14.5.2.HDP

 - 确保设置IGNITE_HOME环境变量，指向Ignite Hadoop加速器的解压目录；
 - 打开**Ambari**Web应用然后关闭如下的服务：HDFS, MapReduce2和YARN；
 - 将Ignite的jars`${IGNITE_HOME}\libs\ignite-core-[version].jar`和`${GNITE_HOME}\libs\hadoop\ignite-hadoop-[version].jar`加入HDP的类路径，要做到这一点打开**HDFS**->**Configs**->**Advanced hadoop-env**，然后编辑**hadoop-env template**属性，找到第一个`HADOOP_CLASSPATH`的export，他可能像下面这样：
```shell
export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}${JAVA_JDBC_LIBS}:${MAPREDUCE_LIBS}
```
在这一行之后加入：
```shell
export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}:${IGNITE_HOME}/libs/ignite-core-1.0.0.jar:${IGNITE_HOME}/libs/hadoop/ignite-hadoop-1.0.0.jar
```
 - 如果希望使用Ignite`文件系统`，可以在独立的`core-site.xml`文件中进行配置。
```xml
<configuration>
  ...
  <property>
    <name>fs.default.name</name>
    <value>igfs:///</value>
  </property>
  ...
  <property>
    <name>fs.igfs.impl</name>
    <value>org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem</value>
  </property>  
  ...
</configuration>
```
作为替代也可以在默认的`core-site.xml`中配置`fs.igfs.impl`属性，打开**HDFS**->**Configs**->**Custom core-site**然后加入`fs.igfs.impl`属性，值为`org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem`。
同时，也可以在默认的`core-site.xml`中配置`fs.default.name`属性，打开**HDFS**->**Configs**->**Advanced core-site**然后加入`fs.default.name`属性，值为`igfs:///`。
注意如果改变了位于默认的`core-site.xml`中的`fs.default.name`来使用Ignite文件系统，HDP就不会再使用`HDFS`,如果希望同时使用Ignite`文件系统`和`HDFS`,可以考虑创建单独的配置文件。

 - 如果希望使用Ignite`MapReduce`作业跟踪器，可以在独立的`mapred-site.xml`文件中进行配置：
XML：
```xml
<configuration>
  ...
  <property>
    <name>mapreduce.framework.name</name>
    <value>ignite</value>
  </property>
  <property>
    <name>mapreduce.jobtracker.address</name>
    <value>127.0.0.1:11211</value>
  </property>
  ...
</configuration>
```
作为替代也可以在默认的HDP`mapred-site.xml`中配置这些属性：
1）在系统的任意位置创建一个压缩包（比如名为`dummy.tar.gz`）；
2）打开**MapReduce2**->**Configs**->**Advanced mapred-site**然后改变如下的属性值：`mapreduce.framework.name = ignite`和`mapreduce.application.framework.path = /path/to/dummy.tar.gz`，后者是必须的，因为HDP需要定义Hadoop框架的压缩包但是对于Ignite是没有意义的；
3）打开**MapReduce2**->**Configs**->**Custom mapred-site**然后改变如下的属性值：`mapreduce.jobtracker.address = 127.0.0.1:11211`。

 - 如果对默认的配置做了任何改变，需要保存然后重新启动所有的HDP服务。
 - 到这一步安装已经完成然后就可以启动运行作业了。
可以通过单独的`core-site.xml`以及/或者`mapred-site.xml`配置文件来运行作业：
```shell
hadoop --config [path_to_config] [arguments]
```
通过默认的配置运行作业:
```shell
hadoop [arguments]
```
## 14.6.Ignite和Apache Hive
本章节描述如果在经过Ignite加速后的Hadoop上正确配置和启动Hive，还显示了如何启动HiveServer2以及该配置下的一个远程客户端。
### 14.6.1.前提条件
假定Hadoop已经安装和配置好以运行在Ignite上，然后配置了IGFS文件系统以及MapReduce作业跟踪器功能的Ignite节点也已经启动运行。
还需要安装Hive：[http://hive.apache.org/](http://hive.apache.org/)。
### 14.6.2.启动Hive
下面是在`Ignited`的Hadoop上运行Hive的必要步骤：

 - 提供可执行的`Hadoop`的正确位置，这个可以通过将可执行文件的路径加入`PATH`环境变量（注意可执行的文件大都位于一个叫做`bin/`的文件夹），或者通过指定`HADOOP_HOME`环境变量实现；
 - 提供配置文件的位置（`core-site.xml`,`hive-site.xml`,`mapred-site.xml`），这个可以通过将这些文件放入一个目录然后将该目录的路径作为`HIVE_CONF_DIR`环境变量值来实现。

> 配置模板
建议使用Hive模板配置文件`<IGNITE_HOME>/config/hadoop/hive-site.ignite.xml`来获得Ignite指定的设置。

> 有一个与Hive和Hadoop中的不同`jline`库版本有关的潜在[问题](http://stackoverflow.com/questions/28997441/hive-startup-error-terminal-initialization-failed-falling-back-to-unsupporte)，他可以通过设置`HADOOP_USER_CLASSPATH_FIRST=true`环境变量来解决。

为了方便，也可以创建一个简单的脚本来正确地设置所有必要的变量然后启动Hive，像下面这样：
```shell
# Specify Hive home directory:
export HIVE_HOME=<Hive installation directory>

# Specofy configuration files location:
export HIVE_CONF_DIR=<Path to our configuration folder>

# If you did not set hadoop executable in PATH, specify Hadoop home explicitly:
export HADOOP_HOME=<Hadoop installation folder>

# Avoid problem with different 'jline' library in Hadoop: 
export HADOOP_USER_CLASSPATH_FIRST=true

${HIVE_HOME}/bin/hive "${@}"
```
这个脚本可以用于在交互式控制台上启动Hive：
```shell
$ hive-ig cli
hive> show tables;
OK
u_data
Time taken: 0.626 seconds, Fetched: 1 row(s)
hive> quit;
$
```
### 14.6.3.启动HiveServer2
如果为了增强的客户端功能希望使用[HiveServer2](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2)，要启动它也可以使用上面创建的脚本。
```shell
hive-ig --service hiveserver2
```
服务启动之后，可以使用任何有效的[客户端](https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients)（比如beeline）连接它。作为一个远程客户端，`beeline`可以在任意主机运行，他也不需要任何特别的环境来与`Ignited`Hive一起工作，下面是示例：
```shell
$ ./beeline 
Beeline version 1.2.1 by Apache Hive
beeline> !connect jdbc:hive2://localhost:10000 scott tiger org.apache.hive.jdbc.HiveDriver
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://localhost:10000> show tables;
+-----------+--+
| tab_name  |
+-----------+--+
| u_data    |
+-----------+--+
1 row selected (0.957 seconds)
0: jdbc:hive2://localhost:10000>
```